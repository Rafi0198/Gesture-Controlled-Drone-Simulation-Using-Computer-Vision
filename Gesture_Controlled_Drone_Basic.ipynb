{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HAND RECOGNITION AND LANDMARKS ESTIMATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone import putTextRect\n",
    "from cvzone.FPS import FPS \n",
    "import cv2\n",
    "\n",
    "# Initialize the webcam to capture video\n",
    "# The '2' indicates the third camera connected to your computer; '0' would usually refer to the built-in camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "fpsReader = FPS(avgCount=30)\n",
    "\n",
    "# Initialize the HandDetector class with the given parameters\n",
    "detector = HandDetector(staticMode=False, maxHands=2, modelComplexity=1, detectionCon=0.5, minTrackCon=0.5)\n",
    "\n",
    "# Continuously get frames from the webcam\n",
    "while True:\n",
    "    # Capture each frame from the webcam\n",
    "    # 'success' will be True if the frame is successfully captured, 'img' will contain the frame\n",
    "    success, img = cap.read()\n",
    "\n",
    "    # Find hands in the current frame\n",
    "    # The 'draw' parameter draws landmarks and hand outlines on the image if set to True\n",
    "    # The 'flipType' parameter flips the image, making it easier for some detections\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    # Check if any hands are detected\n",
    "    if hands:\n",
    "        # Information for the first hand detected\n",
    "        hand1 = hands[0]  # Get the first hand detected\n",
    "        lmList1 = hand1[\"lmList\"]  # List of 21 landmarks for the first hand\n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding box around the first hand (x,y,w,h coordinates)\n",
    "        center1 = hand1['center']  # Center coordinates of the first hand\n",
    "        handType1 = hand1[\"type\"]  # Type of the first hand (\"Left\" or \"Right\")\n",
    "\n",
    "        # Count the number of fingers up for the first hand\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "        print(fingers1)\n",
    "\n",
    "        #print(f'H1 = {fingers1.count(1)}', end=\" \")  # Print the count of fingers that are up\n",
    "\n",
    "        # if handType1=='Right' and fingers1[4] and fingers1.count(1)==1: \n",
    "        #     #Take off command\n",
    "   \n",
    "\n",
    "        # Check if a second hand is detected\n",
    "        if len(hands) == 2:\n",
    "            # Information for the second hand\n",
    "            hand2 = hands[1]\n",
    "            lmList2 = hand2[\"lmList\"]\n",
    "            bbox2 = hand2[\"bbox\"]\n",
    "            center2 = hand2['center']\n",
    "            handType2 = hand2[\"type\"]\n",
    "\n",
    "            # Count the number of fingers up for the second hand\n",
    "            fingers2 = detector.fingersUp(hand2)\n",
    "            print(f'H2 = {fingers2.count(1)}', end=\" \")\n",
    "\n",
    "        print(\" \") #Print this for a new line\n",
    "\n",
    "\n",
    "    #fpsReader.update returns the current FPS and the updated image\n",
    "    fps, img = fpsReader.update(img, pos=(10, 470),bgColor=(0, 0, 255), textColor=(255, 255, 255), scale=1.3, thickness=2)\n",
    "    # Display the image in a window\n",
    "    cv2.imshow(\"Drone Simulation\", img)\n",
    "\n",
    "    # Keep the window open and update it for each frame; wait for 1 millisecond between frames\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRONE HEALTH PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dronekit import connect, VehicleMode, LocationGlobalRelative\n",
    "import time \n",
    "\n",
    "# Connect to the Vehicle (use the correct SITL connection string)\n",
    "print(\"Connecting to vehicle on tcp:127.0.0.1:5763 and udp 127.0.0.1:14550\")\n",
    "#vehicle = connect('tcp:127.0.0.1:5762', wait_ready=True)\n",
    "vehicle = connect('127.0.0.1:14550', wait_ready=True)\n",
    "\n",
    "# Print some basic info\n",
    "print(\"=== Vehicle Info ===\")\n",
    "print(f\" Autopilot Firmware version: {vehicle.version}\")\n",
    "print(f\" Global Location: {vehicle.location.global_frame}\")\n",
    "print(f\" Global Location (relative altitude): {vehicle.location.global_relative_frame}\")\n",
    "print(f\" Local Location: {vehicle.location.local_frame}\")  # NED\n",
    "print(f\" Attitude: {vehicle.attitude}\")\n",
    "print(f\" Velocity: {vehicle.velocity}\")\n",
    "print(f\" GPS: {vehicle.gps_0}\")\n",
    "print(f\" Battery: {vehicle.battery}\")\n",
    "print(f\" EKF OK?: {vehicle.ekf_ok}\")\n",
    "print(f\" Last Heartbeat: {vehicle.last_heartbeat}\")\n",
    "print(f\" Is Armable?: {vehicle.is_armable}\")\n",
    "print(f\" System status: {vehicle.system_status.state}\")\n",
    "print(f\" Mode: {vehicle.mode.name}\")\n",
    "vehicle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLE TAKE OFF AND RTL WITH STUCK FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dronekit import connect, VehicleMode, LocationGlobalRelative\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.FPS import FPS \n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# -------------------- DroneKit Setup --------------------\n",
    "print(\"[INFO] Connecting to vehicle...\")\n",
    "vehicle = connect('127.0.0.1:14550', wait_ready=True)\n",
    "\n",
    "def change_mode(mode_name):\n",
    "    print(f\"[INFO] Changing mode to {mode_name}...\")\n",
    "    vehicle.mode = VehicleMode(mode_name)\n",
    "    while vehicle.mode.name != mode_name:\n",
    "        print(f\"[INFO] Waiting for mode change to {mode_name}...\")\n",
    "        time.sleep(1)\n",
    "    print(f\"[INFO] Mode changed to {vehicle.mode.name}\")\n",
    "\n",
    "def arm_and_takeoff(target_altitude):\n",
    "    change_mode(\"GUIDED\")\n",
    "\n",
    "    print(\"[INFO] Arming motors...\")\n",
    "    vehicle.armed = True\n",
    "    while not vehicle.armed:\n",
    "        print(\"[INFO] Waiting for arming...\")\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"[INFO] Taking off to {target_altitude} meters...\")\n",
    "    vehicle.simple_takeoff(target_altitude)\n",
    "\n",
    "    while True:\n",
    "        current_alt = vehicle.location.global_relative_frame.alt\n",
    "        print(f\"[INFO] Current Altitude: {current_alt:.2f} meters\")\n",
    "        if current_alt >= target_altitude * 0.95:\n",
    "            print(\"[INFO] Target altitude reached\")\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "# -------------------- Hand Detection Setup --------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "fpsReader = FPS(avgCount=30)\n",
    "detector = HandDetector(staticMode=False, maxHands=2, modelComplexity=1, detectionCon=0.6, minTrackCon=0.5)\n",
    "\n",
    "# Flags to avoid repeated triggering\n",
    "\n",
    "has_taken_off = False\n",
    "rtl_triggered = False\n",
    "\n",
    "print(\"[INFO] Starting gesture detection...\")\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    if hands:\n",
    "        hand1 = hands[0]\n",
    "        handType1 = hand1[\"type\"]\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "\n",
    "        #print(f\"[INFO] Right hand fingers up: {fingers1} => Count: {fingers1.count(1)}\")\n",
    "\n",
    "        # ðŸ›« Takeoff if right thumb only is up\n",
    "        if handType1 == 'Right' and fingers1[0] and fingers1.count(1) == 1 and not has_taken_off:\n",
    "            print(\"[GESTURE] Right thumb detected â€” initiating TAKEOFF...\")\n",
    "            arm_and_takeoff(12)\n",
    "            has_taken_off = True\n",
    "            rtl_triggered = False  # Reset RTL flag just in case\n",
    "\n",
    "        # ðŸ RTL if all five fingers are up\n",
    "        elif handType1 == 'Right' and fingers1.count(1) == 5 and has_taken_off and not rtl_triggered:\n",
    "            print(\"[GESTURE] All five fingers detected â€” initiating RTL...\")\n",
    "            change_mode(\"RTL\")\n",
    "            rtl_triggered = True\n",
    "\n",
    "    # Display video feed\n",
    "    cv2.imshow(\"Drone Gesture Control\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "print(\"[INFO] Closing connection and camera...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "vehicle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAKE OFF AND RTL WITH VISUALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connecting to vehicle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:autopilot:APM:Copter V3.3 (d6053245)\n",
      "CRITICAL:autopilot:Frame: QUAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting gesture detection...\n",
      "[GESTURE] Right thumb detected â€” TAKEOFF initiated\n",
      "[INFO] Changing mode to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:ARMING MOTORS\n",
      "CRITICAL:autopilot:Initialising APM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Mode changed to GUIDED\n",
      "[INFO] Motors armed â€” taking off now...\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.07 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 0.50 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 1.21 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 2.07 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 3.04 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 4.07 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 5.14 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 6.26 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 7.40 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 8.55 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 9.63 m\n",
      "[INFO] Altitude: 11.72 m\n",
      "[INFO] Target altitude reached âœ…\n",
      "[GESTURE] All five fingers detected â€” initiating RTL\n",
      "[INFO] Changing mode to RTL...\n",
      "[INFO] Waiting for mode change to RTL...\n",
      "[INFO] Mode changed to RTL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:DISARMING MOTORS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GESTURE] Right thumb detected â€” TAKEOFF initiated\n",
      "[INFO] Changing mode to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:ARMING MOTORS\n",
      "CRITICAL:autopilot:Initialising APM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Mode changed to GUIDED\n",
      "[INFO] Motors armed â€” taking off now...\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.00 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.06 m\n",
      "[INFO] Altitude: 0.47 m\n",
      "[INFO] Altitude: 0.47 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 2.98 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 4.01 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 5.08 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 6.19 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 7.33 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 8.48 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 9.57 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 10.49 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.13 m\n",
      "[INFO] Altitude: 11.50 m\n",
      "[INFO] Target altitude reached âœ…\n",
      "[GESTURE] All five fingers detected â€” initiating RTL\n",
      "[INFO] Changing mode to RTL...\n",
      "[INFO] Waiting for mode change to RTL...\n",
      "[INFO] Mode changed to RTL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:DISARMING MOTORS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Closing connection and camera...\n"
     ]
    }
   ],
   "source": [
    "from dronekit import connect, VehicleMode, LocationGlobalRelative\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone import putTextRect\n",
    "from cvzone.FPS import FPS \n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# -------------------- DroneKit Setup --------------------\n",
    "print(\"[INFO] Connecting to vehicle...\")\n",
    "vehicle = connect('127.0.0.1:14550', wait_ready=True)\n",
    "\n",
    "def change_mode(mode_name):\n",
    "    print(f\"[INFO] Changing mode to {mode_name}...\")\n",
    "    vehicle.mode = VehicleMode(mode_name)\n",
    "    while vehicle.mode.name != mode_name:\n",
    "        print(f\"[INFO] Waiting for mode change to {mode_name}...\")\n",
    "        time.sleep(0.5)\n",
    "    print(f\"[INFO] Mode changed to {vehicle.mode.name}\")\n",
    "\n",
    "# -------------------- Hand Detection Setup --------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "fpsReader = FPS(avgCount=30)\n",
    "detector = HandDetector(staticMode=False, maxHands=2, modelComplexity=1, detectionCon=0.6, minTrackCon=0.5)\n",
    "\n",
    "# Flags and state tracking\n",
    "takeoff_requested = False\n",
    "taking_off = False\n",
    "rtl_triggered = False\n",
    "target_altitude = 12\n",
    "start_takeoff_time = None\n",
    "\n",
    "print(\"[INFO] Starting gesture detection...\")\n",
    "while True:\n",
    "    # Capture and show webcam frame\n",
    "    success, img = cap.read()\n",
    "    H,W,_ = img.shape\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    # Read current altitude for feedback\n",
    "    current_alt = vehicle.location.global_relative_frame.alt\n",
    "\n",
    "    if hands:\n",
    "        hand1 = hands[0]\n",
    "        handType1 = hand1[\"type\"]\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "\n",
    "        #print(f\"[INFO] Right hand fingers up: {fingers1} => Count: {fingers1.count(1)}\")\n",
    "\n",
    "        # ðŸ›« Takeoff Gesture â€” only right thumb up\n",
    "        if handType1 == 'Right' and fingers1[4] and fingers1.count(1) == 1:\n",
    "            if not takeoff_requested and not taking_off:\n",
    "                print(\"[GESTURE] Right thumb detected â€” TAKEOFF initiated\")\n",
    "                change_mode(\"GUIDED\")\n",
    "                vehicle.armed = True\n",
    "                takeoff_requested = True\n",
    "                start_takeoff_time = time.time()\n",
    "\n",
    "        # ðŸ RTL Gesture â€” all five fingers up\n",
    "        if handType1 == 'Right' and fingers1.count(1) == 5:\n",
    "            if not rtl_triggered and  not taking_off and current_alt  > 1.5:  # Ensure we're in air\n",
    "                print(\"[GESTURE] All five fingers detected â€” initiating RTL\")\n",
    "                change_mode(\"RTL\")\n",
    "                rtl_triggered = True\n",
    "                takeoff_requested = False\n",
    "                taking_off = False\n",
    "\n",
    "    # â³ Handle Takeoff Progress\n",
    "    if takeoff_requested:\n",
    "        if vehicle.armed:\n",
    "            print(\"[INFO] Motors armed â€” taking off now...\")\n",
    "            vehicle.simple_takeoff(target_altitude)\n",
    "            taking_off = True\n",
    "            takeoff_requested = False\n",
    "\n",
    "    if taking_off:\n",
    "        current_alt = vehicle.location.global_relative_frame.alt\n",
    "        print(f\"[INFO] Altitude: {current_alt:.2f} m\")\n",
    "        if current_alt >= target_altitude * 0.95:\n",
    "            print(\"[INFO] Target altitude reached âœ…\")\n",
    "            taking_off = False\n",
    "            rtl_triggered = False\n",
    "\n",
    "    putTextRect(img, text=f'ALTITUDE:{current_alt}m', pos=(int(W*0.34), 450), scale=1.3,  #W-W*0.3 , 50, 100 \n",
    "                        thickness=2, colorR=(0,0,210), offset=8, border=3, colorB=(0,0,0) )\n",
    "                        \n",
    "    putTextRect(img, text=f'MODE: {vehicle.mode.name}', pos=(int(W*0.34), 400), scale=1.3, \n",
    "                        thickness=2, colorR=(51,51,0), offset=8, border=3, colorB=(0,0,0) )\n",
    "    #fpsReader.update returns the current FPS and the updated image\n",
    "    fps, img = fpsReader.update(img, pos=(10, 470),bgColor=(0, 0, 255), textColor=(255, 255, 255), scale=1.3, thickness=2)\n",
    "    # Show camera feedq\n",
    "    cv2.imshow(\"Drone Gesture Control\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "print(\"[INFO] Closing connection and camera...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "vehicle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADVANCE MOVEMENTS USING GESTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:autopilot:APM:Copter V3.3 (d6053245)\n",
      "CRITICAL:autopilot:Frame: QUAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connecting to vehicle...\n",
      "[INFO] Starting gesture detection...\n",
      "[GESTURE] Right thumb detected â€” TAKEOFF initiated\n",
      "[INFO] Changing mode to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:ARMING MOTORS\n",
      "CRITICAL:autopilot:Initialising APM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Mode changed to GUIDED\n",
      "[INFO] Motors armed â€” taking off now...\n",
      "[INFO] Target altitude reached âœ…\n",
      "[CMD] Increase Altitude +5m\n",
      "[INFO] Command sent: N:0 E:0 ALT:21.99\n",
      "[INFO] Reached target location.\n",
      "[CMD] Decrease Altitude -5m\n",
      "[INFO] Command sent: N:0 E:0 ALT:11.92\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Forward +5m\n",
      "[INFO] Command sent: N:10.0 E:0 ALT:11.92\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Forward +5m\n",
      "[INFO] Command sent: N:10.0 E:0 ALT:11.95\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Right +5m\n",
      "[INFO] Command sent: N:0 E:10.0 ALT:11.94\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Forward +5m\n",
      "[INFO] Command sent: N:10.0 E:0 ALT:11.92\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Left -5m\n",
      "[INFO] Command sent: N:0 E:-10.0 ALT:11.89\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Left -5m\n",
      "[INFO] Command sent: N:0 E:-10.0 ALT:11.88\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Backward -5m\n",
      "[INFO] Command sent: N:-10.0 E:0 ALT:11.90\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Right +5m\n",
      "[INFO] Command sent: N:0 E:10.0 ALT:11.90\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Right +5m\n",
      "[INFO] Command sent: N:0 E:10.0 ALT:11.88\n",
      "[INFO] Reached target location.\n",
      "[CMD] Move Right +5m\n",
      "[INFO] Command sent: N:0 E:10.0 ALT:11.86\n",
      "[INFO] Reached target location.\n",
      "[GESTURE] All five fingers detected â€” initiating RTL\n",
      "[INFO] Changing mode to RTL...\n",
      "[INFO] Waiting for mode change to RTL...\n",
      "[INFO] Waiting for mode change to RTL...\n",
      "[INFO] Mode changed to RTL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:DISARMING MOTORS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Closing connection and camera...\n"
     ]
    }
   ],
   "source": [
    "from dronekit import connect, VehicleMode, LocationGlobalRelative\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone import putTextRect\n",
    "from cvzone.FPS import FPS \n",
    "import cv2\n",
    "import time\n",
    "import math \n",
    "\n",
    "# -------------------- DroneKit Setup --------------------\n",
    "print(\"[INFO] Connecting to vehicle...\")\n",
    "vehicle = connect('127.0.0.1:14550', wait_ready=True)\n",
    "\n",
    "# ---------------- Helper Functions ----------------\n",
    "def get_distance_meters(loc1, loc2):\n",
    "    \"\"\"Calculate approximate ground distance between two LocationGlobalRelative points.\"\"\"\n",
    "    dlat = loc2.lat - loc1.lat\n",
    "    dlon = loc2.lon - loc1.lon\n",
    "    dalt = loc2.alt - loc1.alt\n",
    "    return math.sqrt((dlat * 111139.0)**2 + (dlon * 111139.0 * math.cos(math.radians(loc1.lat)))**2 + (dalt)**2)\n",
    "\n",
    "def goto_relative(north=0, east=0, down=0):\n",
    "    \"\"\"Move drone relative to its current position and update global target.\"\"\"\n",
    "    global moving, target_location\n",
    "\n",
    "    current = vehicle.location.global_relative_frame\n",
    "    new_lat = current.lat + (north / 111139.0)\n",
    "    new_lon = current.lon + (east / (111139.0 * math.cos(math.radians(current.lat))))\n",
    "    new_alt = current.alt - down  # Positive down = lower altitude\n",
    "\n",
    "    target_location = LocationGlobalRelative(new_lat, new_lon, new_alt)\n",
    "    vehicle.simple_goto(target_location)\n",
    "    moving = True\n",
    "    print(f\"[INFO] Command sent: N:{north} E:{east} ALT:{new_alt:.2f}\")\n",
    "\n",
    "def change_mode(mode_name):\n",
    "    print(f\"[INFO] Changing mode to {mode_name}...\")\n",
    "    vehicle.mode = VehicleMode(mode_name)\n",
    "    while vehicle.mode.name != mode_name:\n",
    "        print(f\"[INFO] Waiting for mode change to {mode_name}...\")\n",
    "        time.sleep(0.5)\n",
    "    print(f\"[INFO] Mode changed to {vehicle.mode.name}\")\n",
    "\n",
    "# -------------------- Hand Detection Setup --------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "fpsReader = FPS(avgCount=30)\n",
    "detector = HandDetector(staticMode=False, maxHands=2, modelComplexity=1, detectionCon=0.6, minTrackCon=0.5)\n",
    "\n",
    "# Flags and state tracking\n",
    "takeoff_requested = False\n",
    "taking_off = False\n",
    "rtl_triggered = False\n",
    "in_air = False \n",
    "target_altitude = 12\n",
    "start_takeoff_time = None\n",
    "\n",
    "# Movement step in meters\n",
    "STEP = 10.0\n",
    "# Threshold to check if vehicle has reached target (in meters)\n",
    "DISTANCE_THRESHOLD = 1.0\n",
    "# Flag to indicate whether the drone is already executing a movement\n",
    "moving = False\n",
    "target_location = None  # Will store the latest target LocationGlobalRelative\n",
    "\n",
    "print(\"[INFO] Starting gesture detection...\")\n",
    "while True:\n",
    "    # Capture and show webcam frame\n",
    "    success, img = cap.read()\n",
    "    H,W,_ = img.shape\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    # Read current altitude for feedback\n",
    "    current_alt = vehicle.location.global_relative_frame.alt\n",
    "\n",
    "      # Check if movement completed ----------------\n",
    "    if moving and target_location is not None:\n",
    "        current = vehicle.location.global_relative_frame\n",
    "        dist = get_distance_meters(current, target_location)\n",
    "        putTextRect(img, text=f'MOVING:{dist:.2f}m AWAY', pos=(int(W*0.34), 350), scale=1.3,  #W-W*0.3 , 50, 100 \n",
    "                        thickness=2, colorR=(0,0,210), offset=8, border=3, colorB=(0,0,0) )\n",
    "        if dist < DISTANCE_THRESHOLD:\n",
    "            print(\"[INFO] Reached target location.\")\n",
    "            moving = False  # Allow next command\n",
    "\n",
    "    if hands:\n",
    "        hand1 = hands[0]\n",
    "        handType1 = hand1[\"type\"]\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "\n",
    "        #print(f\"[INFO] Right hand fingers up: {fingers1} => Count: {fingers1.count(1)}\")\n",
    "\n",
    "        # ðŸ›« Takeoff Gesture â€” only right thumb up\n",
    "        if handType1 == 'Right' and fingers1[0] and fingers1.count(1) == 1 and not vehicle.armed:\n",
    "            if not takeoff_requested and not taking_off:\n",
    "                print(\"[GESTURE] Right thumb detected â€” TAKEOFF initiated\")\n",
    "                change_mode(\"GUIDED\")\n",
    "                vehicle.armed = True\n",
    "                takeoff_requested = True\n",
    "                start_takeoff_time = time.time()\n",
    "\n",
    "        # ðŸ RTL Gesture â€” all five fingers up\n",
    "        if handType1 == 'Right' and fingers1.count(1) == 5:\n",
    "            if not rtl_triggered and  not taking_off and current_alt  > 1.5:  # Ensure we're in air\n",
    "                print(\"[GESTURE] All five fingers detected â€” initiating RTL\")\n",
    "                change_mode(\"RTL\")\n",
    "                rtl_triggered = True\n",
    "                takeoff_requested = False\n",
    "                taking_off = False\n",
    "                in_air = False\n",
    "                moving = False \n",
    "                \n",
    "        if in_air and not moving:\n",
    "            # Right Hand: Increase Altitude\n",
    "            if handType1 == \"Right\" and fingers1[1] and fingers1[2] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Increase Altitude +5m\")\n",
    "                goto_relative(down=-STEP)\n",
    "\n",
    "            # Right Hand: Decrease Altitude\n",
    "            elif handType1 == \"Right\" and fingers1[1] and fingers1[4] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Decrease Altitude -5m\")\n",
    "                goto_relative(down=STEP)\n",
    "\n",
    "            # Right Hand: Move Right\n",
    "            elif handType1 == \"Right\" and fingers1[0] and fingers1[1] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Move Right +5m\")\n",
    "                goto_relative(east=STEP)\n",
    "\n",
    "            # Left Hand: Move Left\n",
    "            elif handType1 == \"Left\" and fingers1[0] and fingers1[1] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Move Left -5m\")\n",
    "                goto_relative(east=-STEP)\n",
    "\n",
    "            # Move Forward (+5m North)\n",
    "            elif handType1 == \"Left\" and fingers1[1] and fingers1[2] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Move Forward +5m\")\n",
    "                goto_relative(north=STEP)\n",
    "\n",
    "            # Move Backward (-5m North)\n",
    "            elif handType1 == \"Left\" and fingers1[1] and fingers1[4] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Move Backward -5m\")\n",
    "                goto_relative(north=-STEP)\n",
    "\n",
    "    # â³ Handle Takeoff Progress\n",
    "    if takeoff_requested:\n",
    "        if vehicle.armed:\n",
    "            print(\"[INFO] Motors armed â€” taking off now...\")\n",
    "            vehicle.simple_takeoff(target_altitude)\n",
    "            taking_off = True\n",
    "            takeoff_requested = False\n",
    "\n",
    "    if taking_off:\n",
    "        current_alt = vehicle.location.global_relative_frame.alt\n",
    "        #print(f\"[INFO] Altitude: {current_alt:.2f} m\")\n",
    "        if current_alt >= target_altitude * 0.95:\n",
    "            print(\"[INFO] Target altitude reached âœ…\")\n",
    "            taking_off = False\n",
    "            rtl_triggered = False\n",
    "            in_air = True \n",
    "\n",
    "    putTextRect(img, text=f'ALTITUDE:{current_alt}m', pos=(int(W*0.34), 450), scale=1.3,  #W-W*0.3 , 50, 100 \n",
    "                        thickness=2, colorR=(0,0,210), offset=8, border=3, colorB=(0,0,0) )\n",
    "                        \n",
    "    putTextRect(img, text=f'MODE: {vehicle.mode.name}', pos=(int(W*0.34), 400), scale=1.3, \n",
    "                        thickness=2, colorR=(51,51,0), offset=8, border=3, colorB=(0,0,0) )\n",
    "    #fpsReader.update returns the current FPS and the updated image\n",
    "    fps, img = fpsReader.update(img, pos=(10, 470),bgColor=(0, 0, 255), textColor=(255, 255, 255), scale=1.3, thickness=2)\n",
    "    # Show camera feedq\n",
    "    cv2.imshow(\"Drone Gesture Control\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "print(\"[INFO] Closing connection and camera...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "vehicle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIRTUAL DYNAMIC BUTTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone import putTextRect\n",
    "from cvzone.FPS import FPS \n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "# Initialize the webcam to capture video\n",
    "# The '2' indicates the third camera connected to your computer; '0' would usually refer to the built-in camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "fpsReader = FPS(avgCount=30)\n",
    "\n",
    "# Initialize the HandDetector class with the given parameters\n",
    "detector = HandDetector(staticMode=False, maxHands=2, modelComplexity=1, detectionCon=0.5, minTrackCon=0.5)\n",
    "cxrect,cyrect,wrect, hrect = 200,200,100,100\n",
    "alpha=0.5\n",
    "movement= False \n",
    "colorR = 55,55,0\n",
    "\n",
    "\n",
    "# Continuously get frames from the webcam\n",
    "while True:\n",
    "    # Capture each frame from the webcam\n",
    "    # 'success' will be True if the frame is successfully captured, 'img' will contain the frame\n",
    "    success, img = cap.read()\n",
    "    H,W,_ = img.shape  #H,W = 480, 640\n",
    "    #print(H,W)\n",
    "\n",
    "    # Configure the virtual zone\n",
    "\n",
    "    x1zone, y1zone, x2zone, y2zone = int(W*0.2), int(H*0.2), int(W*0.8), int(H*0.8) \n",
    "    wzone = int(x2zone-x1zone)\n",
    "    hzone = int(y2zone-y1zone)\n",
    "    cxzone, cyzone = int((x1zone+x2zone)//2), int((y1zone+y2zone)//2)\n",
    "    cv2.circle(img, (cxzone,cyzone), 6, (255,0,0), cv2.FILLED)\n",
    "\n",
    "\n",
    "    cv2.rectangle(img, (x1zone,y1zone), (x2zone,y2zone), (25,0,51),3)\n",
    "    #cv2.rectangle(img, (int(200),int(200)), (int(220),int(220)), (0,0,0),cv2.FILLED)\n",
    "\n",
    "    # Find hands in the current frame\n",
    "    # The 'draw' parameter draws landmarks and hand outlines on the image if set to True\n",
    "    # The 'flipType' parameter flips the image, making it easier for some detections\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    # Check if any hands are detected\n",
    "    if hands:\n",
    "        # Information for the first hand detected\n",
    "        hand1 = hands[0]  # Get the first hand detected\n",
    "        lmList1 = hand1[\"lmList\"]  # List of 21 landmarks for the first hand\n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding box around the first hand (x,y,w,h coordinates)\n",
    "        center1 = hand1['center']  # Center coordinates of the first hand\n",
    "        handType1 = hand1[\"type\"]  # Type of the first hand (\"Left\" or \"Right\")\n",
    "        length, info, img = detector.findDistance(lmList1[8][0:2], lmList1[12][0:2], img, color=(0, 0, 255),scale=10) #Thumb and later\n",
    "        \n",
    "        cx1, cy1 = center1\n",
    "        cv2.line(img, (cx1,0),(cx1,H), (0,0,255),4)\n",
    "        cv2.line(img, (0,cy1),(W,cy1), (0,0,255),4)\n",
    "        cv2.circle(img, (cx1,cy1), 6, (0,255,0), cv2.FILLED)\n",
    "\n",
    "        if cx1>int(W*0.2) and cx1<int(W*0.8) and cy1>int(H*0.2) and cy1< int(H*0.8): \n",
    "\n",
    "            if length<40: \n",
    "                if cx1>int(cxrect-wrect*0.5) and cx1<int(cxrect+wrect*0.5) and cy1>int(cyrect-hrect*0.5) and cy1< int(cyrect+hrect*0.5):\n",
    "                    colorR = 0,255,0\n",
    "                    cxrect, cyrect = cx1, cy1\n",
    "\n",
    "                    dx_pixels = cx1 - cxzone\n",
    "                    dy_pixels = cyzone - cy1  # Invert Y\n",
    "\n",
    "                    east_offset = np.interp(dx_pixels, [-wzone*0.5, wzone*0.5], [-80, 80])\n",
    "                    north_offset = np.interp(dy_pixels, [-hzone*0.5, hzone*0.5], [-80, 80])\n",
    "                    putTextRect(img, text=f'D: {east_offset:0.2f},{north_offset:0.2f}', pos=(int(W*0.34), 400), scale=1.3, \n",
    "                        thickness=2, colorR=(51,51,0), offset=8, border=3, colorB=(0,0,0) )\n",
    "                    movement = True \n",
    "                else: \n",
    "                    colorR = 55,55,0\n",
    "            else: \n",
    "                    colorR = 55,55,0\n",
    "                    movement = False\n",
    "                    \n",
    "        \n",
    "        #cv2.rectangle(img, (int(cxrect-wrect*0.5),int(cyrect-hrect*0.5)), (int(cxrect+wrect*0.5),int(cyrect+hrect*0.5)), colorR, cv2.FILLED)\n",
    "        \n",
    "        # Create a copy of the image to draw the overlay\n",
    "        overlay = img.copy()\n",
    "        # Draw the filled rectangle on the overlay image\n",
    "        cv2.rectangle(overlay,\n",
    "                    (int(cxrect - wrect * 0.5), int(cyrect - hrect * 0.5)),\n",
    "                    (int(cxrect + wrect * 0.5), int(cyrect + hrect * 0.5)),\n",
    "                    colorR, thickness=cv2.FILLED)\n",
    "\n",
    "        # Blend the overlay with the original image\n",
    "        cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n",
    "\n",
    "\n",
    "\n",
    "            # Count the number of fingers up for the first hand\n",
    "            #fingers1 = detector.fingersUp(hand1)\n",
    "            #print(fingers1)\n",
    "\n",
    "            #print(f'H1 = {fingers1.count(1)}', end=\" \")  # Print the count of fingers that are up\n",
    "\n",
    "\n",
    "        # Check if a second hand is detected\n",
    "        if len(hands) == 2:\n",
    "            # Information for the second hand\n",
    "            hand2 = hands[1]\n",
    "            lmList2 = hand2[\"lmList\"]\n",
    "            bbox2 = hand2[\"bbox\"]\n",
    "            center2 = hand2['center']\n",
    "            handType2 = hand2[\"type\"]\n",
    "\n",
    "            #Count the number of fingers up for the second hand\n",
    "            fingers2 = detector.fingersUp(hand2)\n",
    "        #     print(f'H2 = {fingers2.count(1)}', end=\" \")\n",
    "\n",
    "\n",
    "\n",
    "    #fpsReader.update returns the current FPS and the updated image\n",
    "    fps, img = fpsReader.update(img, pos=(10, 470),bgColor=(0, 0, 255), textColor=(255, 255, 255), scale=1.3, thickness=2)\n",
    "    # Display the image in a window\n",
    "    cv2.imshow(\"Drone Simulation\", img)\n",
    "\n",
    "    # Keep the window open and update it for each frame; wait for 1 millisecond between frames\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAPPED POSITIONAL GESTURE BASED CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connecting to vehicle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:autopilot:APM:Copter V3.3 (d6053245)\n",
      "CRITICAL:autopilot:Frame: QUAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting gesture detection...\n",
      "[GESTURE] Right thumb detected â€” TAKEOFF initiated\n",
      "[INFO] Changing mode to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n",
      "[INFO] Waiting for mode change to GUIDED...\n",
      "[INFO] Mode changed to GUIDED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:ARMING MOTORS\n",
      "CRITICAL:autopilot:GROUND START\n",
      "CRITICAL:autopilot:Initialising APM...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Motors armed â€” taking off now...\n",
      "[INFO] Target altitude reached âœ…\n",
      "[CMD] Increase Altitude +5m\n",
      "[INFO] Command sent: N:0 E:0 ALT:21.98\n",
      "[INFO] Reached target location.\n",
      "[CMD] Decrease Altitude -5m\n",
      "[INFO] Command sent: N:0 E:0 ALT:11.96\n",
      "[INFO] Reached target location.\n",
      "[CMD] Moving to target-49.17,50.56m\n",
      "[INFO] Command sent: N:50.55555555555557 E:-49.166666666666664 ALT:11.98\n",
      "[INFO] Reached target location.\n",
      "[CMD] Moving to target24.17,-14.44m\n",
      "[INFO] Command sent: N:-14.444444444444443 E:24.16666666666667 ALT:11.96\n",
      "[INFO] Reached target location.\n",
      "[CMD] Moving to target-19.17,60.00m\n",
      "[INFO] Command sent: N:60.0 E:-19.166666666666664 ALT:11.95\n",
      "[INFO] Reached target location.\n",
      "[CMD] Moving to target-2.08,5.00m\n",
      "[INFO] Command sent: N:5.0 E:-2.0833333333333286 ALT:11.94\n",
      "[INFO] Reached target location.\n",
      "[CMD] Increase Altitude +5m\n",
      "[INFO] Command sent: N:0 E:0 ALT:21.92\n",
      "[INFO] Reached target location.\n",
      "[CMD] Moving to target-49.58,-28.89m\n",
      "[INFO] Command sent: N:-28.888888888888886 E:-49.58333333333333 ALT:21.90\n",
      "[INFO] Reached target location.\n",
      "[CMD] Moving to target-11.67,-55.56m\n",
      "[INFO] Command sent: N:-55.55555555555556 E:-11.666666666666657 ALT:21.89\n",
      "[INFO] Reached target location.\n",
      "[GESTURE] All five fingers detected â€” initiating RTL\n",
      "[INFO] Changing mode to RTL...\n",
      "[INFO] Waiting for mode change to RTL...\n",
      "[INFO] Waiting for mode change to RTL...\n",
      "[INFO] Mode changed to RTL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:autopilot:DISARMING MOTORS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Closing connection and camera...\n"
     ]
    }
   ],
   "source": [
    "from dronekit import connect, VehicleMode, LocationGlobalRelative\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone import putTextRect, overlayPNG\n",
    "from cvzone.FPS import FPS \n",
    "import cv2\n",
    "import time\n",
    "import math \n",
    "import numpy as np\n",
    "\n",
    "# -------------------- DroneKit Setup --------------------\n",
    "print(\"[INFO] Connecting to vehicle...\")\n",
    "vehicle = connect('127.0.0.1:14550', wait_ready=True)\n",
    "\n",
    "#Home Parameters\n",
    "lat_home, lon_home = vehicle.location.global_relative_frame.lat, vehicle.location.global_relative_frame.lon\n",
    "\n",
    "# ---------------- Helper Functions ----------------\n",
    "def get_distance_meters(loc1, loc2):\n",
    "    \"\"\"Calculate approximate ground distance between two LocationGlobalRelative points.\"\"\"\n",
    "    dlat = loc2.lat - loc1.lat\n",
    "    dlon = loc2.lon - loc1.lon\n",
    "    dalt = loc2.alt - loc1.alt\n",
    "    return math.sqrt((dlat * 111139.0)**2 + (dlon * 111139.0 * math.cos(math.radians(loc1.lat)))**2 + (dalt)**2)\n",
    "\n",
    "def goto_relative(north=0, east=0, down=0):\n",
    "    \"\"\"Move drone relative to its current position and update global target.\"\"\"\n",
    "    global moving, target_location\n",
    "\n",
    "    current = vehicle.location.global_relative_frame\n",
    "    new_lat = lat_home + (north / 111139.0)\n",
    "    new_lon = lon_home + (east / (111139.0 * math.cos(math.radians(current.lat))))\n",
    "    new_alt = current.alt - down  # Positive down = lower altitude\n",
    "\n",
    "    target_location = LocationGlobalRelative(new_lat, new_lon, new_alt)\n",
    "    vehicle.simple_goto(target_location)\n",
    "    moving = True\n",
    "    print(f\"[INFO] Command sent: N:{north} E:{east} ALT:{new_alt:.2f}\")\n",
    "\n",
    "def change_mode(mode_name):\n",
    "    print(f\"[INFO] Changing mode to {mode_name}...\")\n",
    "    vehicle.mode = VehicleMode(mode_name)\n",
    "    while vehicle.mode.name != mode_name:\n",
    "        print(f\"[INFO] Waiting for mode change to {mode_name}...\")\n",
    "        time.sleep(0.5)\n",
    "    print(f\"[INFO] Mode changed to {vehicle.mode.name}\")\n",
    "\n",
    "# -------------------- Hand Detection Setup --------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "imgDrone = cv2.imread(r'C:\\Users\\hoque\\Desktop\\OpenCV\\DroneKit\\DronePng.png', cv2.IMREAD_UNCHANGED)\n",
    "imgDrone = cv2.resize(imgDrone, (60,60))\n",
    "fpsReader = FPS(avgCount=30)\n",
    "detector = HandDetector(staticMode=False, maxHands=1, modelComplexity=1, detectionCon=0.6, minTrackCon=0.5)\n",
    "cxrect,cyrect,wrect, hrect = 320,240,100,100\n",
    "alpha=0.25\n",
    "colorR=55,55,0\n",
    "\n",
    "# Flags and state tracking\n",
    "takeoff_requested = False\n",
    "taking_off = False\n",
    "rtl_triggered = False\n",
    "in_air = False \n",
    "start_takeoff_time = None\n",
    "movement= False \n",
    "# Flag to indicate whether the drone is already executing a movement\n",
    "moving = False\n",
    "target_location = None  # Will store the latest target LocationGlobalRelative\n",
    "\n",
    "# Movement step in meters\n",
    "STEP = 10.0\n",
    "# Threshold to check if vehicle has reached target (in meters)\n",
    "DISTANCE_THRESHOLD = 1.0\n",
    "target_altitude = 12\n",
    "\n",
    "\n",
    "print(\"[INFO] Starting gesture detection...\")\n",
    "while True:\n",
    "    # Capture and show webcam frame\n",
    "    success, img = cap.read()\n",
    "    H,W,_ = img.shape\n",
    "    x1zone, y1zone, x2zone, y2zone = int(W*0.2), int(H*0.2), int(W*0.8), int(H*0.8) #Coordinates if the virtual zone\n",
    "    wzone = int(x2zone-x1zone)\n",
    "    hzone = int(y2zone-y1zone)\n",
    "    cxzone, cyzone = int((x1zone+x2zone)//2), int((y1zone+y2zone)//2)\n",
    "    cv2.circle(img, (cxzone,cyzone), 6, (255,0,0), cv2.FILLED)\n",
    "\n",
    "\n",
    "    cv2.rectangle(img, (x1zone,y1zone), (x2zone,y2zone), (25,0,51),3)\n",
    "    hands, img = detector.findHands(img, draw=True, flipType=True)\n",
    "\n",
    "    # Read current altitude for feedback\n",
    "    current_alt = vehicle.location.global_relative_frame.alt\n",
    "\n",
    "      # Check if movement completed ----------------\n",
    "    if moving and target_location is not None:\n",
    "        current = vehicle.location.global_relative_frame\n",
    "        dist = get_distance_meters(current, target_location)\n",
    "        putTextRect(img, text=f'MOVING:{dist:.2f}m AWAY', pos=(int(W*0.34), 350), scale=1.3,  #W-W*0.3 , 50, 100 \n",
    "                        thickness=2, colorR=(0,0,210), offset=8, border=3, colorB=(0,0,0) )\n",
    "        if dist < DISTANCE_THRESHOLD:\n",
    "            print(\"[INFO] Reached target location.\")\n",
    "            moving = False  # Allow next command\n",
    "\n",
    "    if hands:\n",
    "       # Information for the first hand detected\n",
    "        hand1 = hands[0]  # Get the first hand detected\n",
    "        lmList1 = hand1[\"lmList\"]  # List of 21 landmarks for the first hand\n",
    "        bbox1 = hand1[\"bbox\"]  # Bounding box around the first hand (x,y,w,h coordinates)\n",
    "        center1 = hand1['center']  # Center coordinates of the first hand\n",
    "        handType1 = hand1[\"type\"]  # Type of the first hand (\"Left\" or \"Right\")\n",
    "        fingers1 = detector.fingersUp(hand1)\n",
    "        \n",
    "        \n",
    "        #cx1, cy1 = center1\n",
    "        cx1, cy1 = lmList1[12][0:2] #8\n",
    "        #print(f\"[INFO] Right hand fingers up: {fingers1} => Count: {fingers1.count(1)}\")\n",
    "\n",
    "        # ðŸ›« Takeoff Gesture â€” only right thumb up\n",
    "        if handType1 == 'Left' and fingers1[0] and fingers1.count(1) == 1 and not vehicle.armed:\n",
    "            if not takeoff_requested and not taking_off:\n",
    "                print(\"[GESTURE] Right thumb detected â€” TAKEOFF initiated\")\n",
    "                change_mode(\"GUIDED\")\n",
    "                vehicle.armed = True\n",
    "                takeoff_requested = True\n",
    "                start_takeoff_time = time.time()\n",
    "\n",
    "        # ðŸ RTL Gesture â€” all five fingers up\n",
    "        if handType1 == 'Left' and fingers1.count(1) == 5:\n",
    "            if not rtl_triggered and  not taking_off and current_alt  > 1.5:  # Ensure we're in air\n",
    "                print(\"[GESTURE] All five fingers detected â€” initiating RTL\")\n",
    "                change_mode(\"RTL\")\n",
    "                rtl_triggered = True\n",
    "                takeoff_requested = False\n",
    "                taking_off = False\n",
    "                in_air = False\n",
    "                moving = False \n",
    "                \n",
    "        if in_air and not moving:\n",
    "            # Right Hand: Increase Altitude\n",
    "            if handType1 == \"Left\" and fingers1[1] and fingers1[2] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Increase Altitude +5m\")\n",
    "                goto_relative(down=-STEP)\n",
    "\n",
    "            # Right Hand: Decrease Altitude\n",
    "            elif handType1 == \"Left\" and fingers1[1] and fingers1[4] and fingers1.count(1) == 2:\n",
    "                print(\"[CMD] Decrease Altitude -5m\")\n",
    "                goto_relative(down=STEP)\n",
    "            \n",
    "            # Positional Logic\n",
    "            if handType1 == 'Right' and cx1>int(W*0.2) and cx1<int(W*0.8) and cy1>int(H*0.2) and cy1< int(H*0.8)\\\n",
    "                                                                                 and not rtl_triggered: \n",
    "               \n",
    "                length, info, img = detector.findDistance(lmList1[8][0:2], lmList1[12][0:2], img, color=(0, 0, 255),scale=10) #Thumb and later\n",
    "                #Draw the coordinates line\n",
    "                cv2.line(img, (cx1,0),(cx1,H), (0,0,255),3)\n",
    "                cv2.line(img, (0,cy1),(W,cy1), (0,0,255),3)\n",
    "                cv2.circle(img, (cx1,cy1), 6, (0,255,0), cv2.FILLED)\n",
    "                \n",
    "                if length<40: \n",
    "                    if cx1>int(cxrect-wrect*0.5) and cx1<int(cxrect+wrect*0.5) and cy1>int(cyrect-hrect*0.5) and cy1< int(cyrect+hrect*0.5):\n",
    "                        colorR = 0,255,0\n",
    "                        cxrect, cyrect = cx1, cy1\n",
    "\n",
    "                        dx_pixels = cx1 - cxzone\n",
    "                        dy_pixels = cyzone - cy1  # Invert Y\n",
    "\n",
    "                        east_offset = np.interp(dx_pixels, [-wzone*0.5, wzone*0.5], [-80, 80])\n",
    "                        north_offset = np.interp(dy_pixels, [-hzone*0.5, hzone*0.5], [-80, 80])\n",
    "                        putTextRect(img, text=f'D: {east_offset:0.2f},{north_offset:0.2f}', pos=(int(cx1)+40, int(cy1)+40), scale=1.1, \n",
    "                            thickness=2, colorR=(51,51,0), offset=7, border=3, colorB=(0,0,0) )\n",
    "                        movement = True \n",
    "                    else: \n",
    "                        colorR = 55,55,0\n",
    "                else:\n",
    "                     if movement: \n",
    "                            print(f\"[CMD] Moving to target{east_offset:0.2f},{north_offset:0.2f}m\")\n",
    "                            goto_relative(north=north_offset, east=east_offset)\n",
    "                            movement = False\n",
    "                            colorR = 55,55,0\n",
    "                \n",
    "                                \n",
    "            else: \n",
    "                colorR = 55,55,0\n",
    "                \n",
    "                \n",
    "    # Create a copy of the image to draw the overlay\n",
    "    overlay = img.copy()\n",
    "    # Draw the filled rectangle on the overlay image\n",
    "    cv2.rectangle(overlay,\n",
    "                (int(cxrect - wrect * 0.5), int(cyrect - hrect * 0.5)),\n",
    "                (int(cxrect + wrect * 0.5), int(cyrect + hrect * 0.5)),\n",
    "                colorR, thickness=cv2.FILLED)\n",
    "    \n",
    "    # Blend the overlay with the original image\n",
    "    cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0, img)\n",
    "    overlayPNG(img, imgDrone, [int(cxrect-30), int(cyrect-30)])\n",
    "\n",
    "    \n",
    "\n",
    "    # â³ Handle Takeoff Progress\n",
    "    if takeoff_requested:\n",
    "        if vehicle.armed:\n",
    "            print(\"[INFO] Motors armed â€” taking off now...\")\n",
    "            vehicle.simple_takeoff(target_altitude)\n",
    "            taking_off = True\n",
    "            takeoff_requested = False\n",
    "\n",
    "    if taking_off:\n",
    "        current_alt = vehicle.location.global_relative_frame.alt\n",
    "        #print(f\"[INFO] Altitude: {current_alt:.2f} m\")\n",
    "        if current_alt >= target_altitude * 0.95:\n",
    "            print(\"[INFO] Target altitude reached âœ…\")\n",
    "            taking_off = False\n",
    "            rtl_triggered = False\n",
    "            in_air = True \n",
    "            moving = False \n",
    "\n",
    "    putTextRect(img, text=f'MODE: {vehicle.mode.name}', pos=(int(W*0.34), 420), scale=1.3, \n",
    "                        thickness=2, colorR=(51,51,0), offset=8, border=3, colorB=(0,0,0) )\n",
    "    putTextRect(img, text=f'ALTITUDE:{current_alt}m', pos=(int(W*0.34), 460), scale=1.3,  #W-W*0.3 , 50, 100 \n",
    "                        thickness=2, colorR=(0,0,210), offset=8, border=3, colorB=(0,0,0) )\n",
    "                        \n",
    "   \n",
    "    #fpsReader.update returns the current FPS and the updated image\n",
    "    fps, img = fpsReader.update(img, pos=(10, 470),bgColor=(0, 0, 255), textColor=(255, 255, 255), scale=1.3, thickness=2)\n",
    "    # Show camera feedq\n",
    "    cv2.imshow(\"Drone Gesture Control\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanupdronekit-sitl copter --home=23.4613785,91.1767227,10,270\n",
    "print(\"[INFO] Closing connection and camera...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "vehicle.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
